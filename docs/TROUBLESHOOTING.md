# üîß Troubleshooting

Guia de solu√ß√£o de problemas comuns do GenAI Eng Prompt.

## Problemas com Vari√°veis de Ambiente

### Problema: Sistema n√£o carrega vari√°veis do arquivo `.env`

**Sintomas:**
- O provedor configurado em `PROVIDER` n√£o √© respeitado
- Sistema usa provedor diferente do configurado
- Erro "API Key inv√°lida" mesmo com chave correta
- Vari√°veis de ambiente aparecem como `undefined`

**Causa:**
O arquivo `.env` n√£o est√° sendo carregado corretamente pelo `dotenv`.

**Solu√ß√£o:**
1. Certifique-se de que o arquivo `.env` existe na raiz do projeto (n√£o apenas `.env.example`):
   ```bash
   ls -la .env
   ```

2. Se n√£o existir, copie do exemplo:
   ```bash
   cp .env.example .env
   ```

3. Edite o `.env` com suas configura√ß√µes reais:
   ```bash
   nano .env  # ou use seu editor preferido
   ```

4. Verifique se as vari√°veis est√£o corretas:
   ```bash
   grep "^PROVIDER=" .env
   grep "^OPENROUTER_API_KEY=" .env
   ```

### Problema: Provedor configurado como `openrouter` mas usa OpenAI

**Sintomas:**
- `.env` tem `PROVIDER=openrouter`
- Logs mostram "Provedor: openai"
- Usa modelo OpenAI em vez do OpenRouter

**Causa:**
Sistema est√° carregando configura√ß√£o do arquivo `config.example.json` em vez do `.env`.

**Solu√ß√£o:**
1. Verifique se o arquivo `.env` existe na raiz do projeto
2. Reinicie o servidor backend completamente
3. Verifique os logs de inicializa√ß√£o:
   - Deve mostrar: `‚úì Configura√ß√£o carregada de vari√°veis de ambiente`
   - N√ÉO deve mostrar: `Usando configura√ß√£o de exemplo (desenvolvimento)`

## Problemas com API Keys

### Problema: "API Key inv√°lida ou n√£o autorizada"

**Sintomas:**
- Erro 401 ao testar conex√£o
- Mensagem: "API Key inv√°lida ou n√£o autorizada"

**Solu√ß√µes:**

1. **Verifique se a API Key est√° correta:**
   ```bash
   # Para OpenRouter
   grep "^OPENROUTER_API_KEY=" .env
   
   # Para OpenAI
   grep "^OPENAI_API_KEY=" .env
   ```

2. **Teste a API Key manualmente:**
   ```bash
   # OpenRouter
   curl https://openrouter.ai/api/v1/models \
     -H "Authorization: Bearer $OPENROUTER_API_KEY"
   
   # OpenAI
   curl https://api.openai.com/v1/models \
     -H "Authorization: Bearer $OPENAI_API_KEY"
   ```

3. **Verifique se h√° espa√ßos ou quebras de linha na API Key:**
   - A API Key deve estar em uma √∫nica linha
   - N√£o deve ter espa√ßos antes ou depois
   - N√£o deve ter aspas

4. **Regenere a API Key:**
   - OpenRouter: https://openrouter.ai/keys
   - OpenAI: https://platform.openai.com/api-keys

### Problema: API Key do OpenRouter n√£o funciona

**Sintomas:**
- API Key come√ßa com `sk-or-v1-`
- Erro 401 ou 403

**Solu√ß√µes:**

1. **Verifique o saldo da conta:**
   - Acesse: https://openrouter.ai/credits
   - OpenRouter requer cr√©ditos pr√©-pagos

2. **Verifique as permiss√µes da chave:**
   - Acesse: https://openrouter.ai/keys
   - Certifique-se de que a chave tem permiss√µes de leitura/escrita

3. **Teste com modelo gratuito:**
   ```env
   OPENROUTER_MODEL=google/gemma-7b-it:free
   ```

## Problemas de Conex√£o

### Problema: "N√£o foi poss√≠vel conectar ao servidor"

**Sintomas:**
- Erro ECONNREFUSED
- Erro ENOTFOUND
- Timeout de conex√£o

**Solu√ß√µes:**

1. **Verifique a conex√£o com a internet:**
   ```bash
   ping -c 3 google.com
   ```

2. **Verifique se a URL est√° correta:**
   ```bash
   # OpenRouter
   grep "^OPENROUTER_BASE_URL=" .env
   # Deve ser: https://openrouter.ai/api/v1
   ```

3. **Teste a conex√£o diretamente:**
   ```bash
   curl -I https://openrouter.ai/api/v1/models
   ```

4. **Verifique firewall/proxy:**
   - Certifique-se de que n√£o h√° bloqueio de sa√≠da na porta 443
   - Configure proxy se necess√°rio

### Problema: Ollama n√£o conecta

**Sintomas:**
- Erro ao conectar com `http://localhost:11434`
- Modelo n√£o encontrado

**Solu√ß√µes:**

1. **Verifique se o Ollama est√° rodando:**
   ```bash
   ollama list
   ```

2. **Inicie o Ollama:**
   ```bash
   ollama serve
   ```

3. **Baixe o modelo:**
   ```bash
   ollama pull granite3.3:8b
   ```

4. **Teste a conex√£o:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

## Problemas de Configura√ß√£o

### Problema: "Provedor n√£o configurado"

**Sintomas:**
- Erro: `Provedor 'xxx' n√£o configurado`
- Sistema n√£o encontra o provedor

**Solu√ß√µes:**

1. **Verifique se as vari√°veis do provedor est√£o definidas:**
   ```bash
   # Para OpenRouter
   grep "^OPENROUTER" .env
   
   # Deve ter pelo menos:
   # OPENROUTER_API_KEY=...
   # OPENROUTER_BASE_URL=...
   # OPENROUTER_MODEL=...
   ```

2. **Verifique se o nome do provedor est√° correto:**
   ```env
   # Nomes v√°lidos:
   PROVIDER=openai
   PROVIDER=anthropic
   PROVIDER=ollama
   PROVIDER=openrouter
   PROVIDER=perplexity
   PROVIDER=openwebui
   PROVIDER=generativa
   ```

3. **Liste os provedores dispon√≠veis:**
   ```bash
   curl http://localhost:3011/api/providers
   ```

### Problema: Modelo n√£o encontrado (404)

**Sintomas:**
- Erro 404: "Modelo n√£o encontrado"
- Mensagem: `O modelo "xxx" n√£o est√° dispon√≠vel`

**Solu√ß√µes:**

1. **Verifique se o modelo est√° dispon√≠vel no provedor:**
   - OpenRouter: https://openrouter.ai/models
   - OpenAI: https://platform.openai.com/docs/models

2. **Use um modelo v√°lido:**
   ```env
   # OpenRouter - modelos populares
   OPENROUTER_MODEL=mistralai/mistral-7b-instruct
   OPENROUTER_MODEL=google/gemma-7b-it:free
   OPENROUTER_MODEL=meta-llama/llama-3-8b-instruct
   
   # OpenAI
   OPENAI_MODEL=gpt-4
   OPENAI_MODEL=gpt-3.5-turbo
   ```

## Problemas de Performance

### Problema: Respostas muito lentas

**Solu√ß√µes:**

1. **Use modelo mais r√°pido:**
   ```env
   # Em vez de gpt-4
   OPENAI_MODEL=gpt-3.5-turbo
   
   # OpenRouter - modelos r√°pidos
   OPENROUTER_MODEL=mistralai/mistral-7b-instruct
   ```

2. **Reduza max_tokens:**
   - Edite as configura√ß√µes no c√≥digo se necess√°rio

3. **Use Ollama local:**
   ```env
   PROVIDER=ollama
   OLLAMA_MODEL=granite3.3:8b
   ```

### Problema: Limite de requisi√ß√µes excedido (429)

**Sintomas:**
- Erro 429: "Too Many Requests"
- Mensagem: "Limite de requisi√ß√µes excedido"

**Solu√ß√µes:**

1. **Aguarde alguns minutos antes de tentar novamente**

2. **Verifique os limites da sua conta:**
   - OpenAI: https://platform.openai.com/account/limits
   - OpenRouter: https://openrouter.ai/credits

3. **Implemente rate limiting no c√≥digo**

4. **Considere upgrade do plano**

## Logs e Debug

### Como ver logs detalhados

1. **Backend:**
   ```bash
   cd backend
   npm run dev
   ```

2. **Verificar vari√°veis de ambiente carregadas:**
   - Procure por: `‚úì Configura√ß√£o carregada de vari√°veis de ambiente`
   - Procure por: `ü§ñ Provedor: xxx`

3. **Testar conex√£o:**
   ```bash
   curl http://localhost:3011/api/health
   ```

### Logs importantes

- `‚úì Configura√ß√£o carregada de vari√°veis de ambiente` - Bom! Usando `.env`
- `Usando configura√ß√£o de exemplo (desenvolvimento)` - Ruim! N√£o encontrou `.env`
- `‚úì Engine xxx inicializada` - Engine criada com sucesso
- `‚úì Conex√£o com xxx estabelecida com sucesso` - Conex√£o OK

## Checklist de Diagn√≥stico

Quando tiver problemas, verifique nesta ordem:

- [ ] Arquivo `.env` existe na raiz do projeto
- [ ] Vari√°vel `PROVIDER` est√° definida corretamente
- [ ] API Key do provedor est√° definida e v√°lida
- [ ] Base URL est√° correta (se aplic√°vel)
- [ ] Modelo existe e est√° dispon√≠vel no provedor
- [ ] H√° conex√£o com a internet
- [ ] Servidor backend est√° rodando
- [ ] Logs mostram "Configura√ß√£o carregada de vari√°veis de ambiente"
- [ ] Logs mostram o provedor correto sendo usado
- [ ] Teste de conex√£o passa com sucesso

## Precisa de Mais Ajuda?

1. **Verifique os logs completos** do backend
2. **Teste a API manualmente** com curl
3. **Consulte a documenta√ß√£o** do provedor espec√≠fico
4. **Abra uma issue** no reposit√≥rio com:
   - Logs completos (sem expor API keys!)
   - Configura√ß√£o usada (sem API keys!)
   - Passos para reproduzir o problema
