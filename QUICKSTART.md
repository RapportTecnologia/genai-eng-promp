# üöÄ Guia de In√≠cio R√°pido

Este guia ir√° ajud√°-lo a colocar o GenAI Eng Prompt em funcionamento rapidamente.

## ‚ö° In√≠cio R√°pido (Desenvolvimento)

### 1. Instale as Depend√™ncias

```bash
# Backend
cd backend
npm install

# Frontend
cd ../frontend
npm install
```

### 2. Configure as Vari√°veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```bash
cp .env.example .env
```

Edite o `.env` e adicione sua API key:

```env
PORT=3010
NODE_ENV=development
PROVIDER=openai

# Adicione sua API key aqui
OPENAI_API_KEY=sk-seu-api-key-aqui
OPENAI_MODEL=gpt-4
```

### 3. Inicie o Backend

```bash
cd backend
npm run dev
```

O backend estar√° rodando em: http://localhost:3010

### 4. Inicie o Frontend (em outro terminal)

```bash
cd frontend
npm run dev
```

O frontend estar√° rodando em: http://localhost:5173

### 5. Acesse a Aplica√ß√£o

Abra seu navegador em: **http://localhost:5173**

## üê≥ In√≠cio R√°pido (Docker)

### 1. Configure o .env

```bash
cp .env.example .env
# Edite o .env com suas API keys
```

### 2. Build e Execute

```bash
docker-compose up -d
```

### 3. Acesse

Abra: **http://localhost:3010**

## üîë Obtendo API Keys

### OpenAI
1. Acesse: https://platform.openai.com/api-keys
2. Crie uma nova API key
3. Adicione ao `.env`: `OPENAI_API_KEY=sk-...`

### Anthropic
1. Acesse: https://console.anthropic.com/
2. Crie uma API key
3. Adicione ao `.env`: `ANTHROPIC_API_KEY=sk-ant-...`

### Ollama (Local - Sem API Key)
1. Instale: https://ollama.ai/
2. Execute: `ollama run llama2`
3. Configure no `.env`:
```env
PROVIDER=ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2
```

## üìù Testando a API

### Health Check
```bash
curl http://localhost:3010/api/health
```

### Otimizar Prompt
```bash
curl -X POST http://localhost:3010/api/optimize \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Escreva uma hist√≥ria sobre um rob√¥"}'
```

## üîß Troubleshooting

### Erro: "Nenhuma configura√ß√£o v√°lida encontrada"
- Verifique se o arquivo `.env` existe na raiz do projeto
- Certifique-se de que pelo menos um provedor est√° configurado com API key v√°lida

### Erro: "Erro de conex√£o"
- Verifique se o backend est√° rodando na porta 3010
- Verifique se n√£o h√° firewall bloqueando a porta

### Frontend n√£o carrega
- Certifique-se de que o backend est√° rodando
- Verifique o console do navegador para erros
- Tente limpar o cache: `Ctrl + Shift + R`

### Ollama n√£o conecta
- Verifique se o Ollama est√° rodando: `ollama list`
- Teste a conex√£o: `curl http://localhost:11434/api/tags`

## üìö Pr√≥ximos Passos

1. Leia o [README.md](README.md) completo
2. Explore os [REQUIREMENTS.md](REQUIREMENTS.md) para entender as funcionalidades
3. Veja o [PLAN.md](PLAN.md) para o roadmap do projeto
4. Consulte o [CHANGELOG.md](CHANGELOG.md) para ver as atualiza√ß√µes

## üí° Dicas

- Use `gpt-3.5-turbo` para testes (mais barato)
- Configure rate limiting em produ√ß√£o
- Use HTTPS em produ√ß√£o
- Monitore o uso de tokens para controlar custos

## üÜò Precisa de Ajuda?

- Abra uma issue no reposit√≥rio
- Consulte a documenta√ß√£o completa no README.md
- Verifique os logs: `docker-compose logs -f` (Docker) ou console do terminal

---

**Pronto! Agora voc√™ pode come√ßar a otimizar seus prompts! ‚ú®**
